#include <HLSLSupport.cginc>
#include "ComplexOperators.compute"
#define _NORMALMAP
#pragma shader_feature PREVIS
#pragma kernel ButterflyHorizontalCompute
#pragma kernel ButterflyVerticalCompute
#pragma kernel TimeSpectrum
#pragma kernel InversionAndPermutation
#pragma kernel FFTCompute
#pragma kernel DebugAmplitude
#ifdef _NORMALMAP
#pragma kernel ComputeNormal
#endif

Texture2D<float4> h0;
Texture2D<float4> _butterflyTexture;
//Apparently, you can pack these in "texture buffers" that have the same access optimization than textures
RWStructuredBuffer<Complex3> pingPong0;
RWStructuredBuffer<Complex3> pingPong1;

#define M_PI 3.1415926535897932
//got rid of the direction variable and simply calling the vertical and horizontal pass separately
CBUFFER_START(FrequentUpdatesVariables)
int direction;
int stage;
int pingPong;//this value is implicitly contained in stage and could be computed using stage & 1
CBUFFER_END

CBUFFER_START(RarelyUpdated)
int N;
int LogN;
int L;
#ifdef _NORMALMAP
float pixelStep;//distance in Unity units between each horizontal pixel (as real dimensions are lost to concession made to float precision)
float HorizontalScaling;
float VerticalScaling;
#endif
CBUFFER_END
RWStructuredBuffer<Complex3> UnifiedFFTBuffer;
RWTexture2D<float4> DebugFFTTexture;
[numthreads(256,1,1)]
void FFTCompute(uint3 id : SV_DispatchThreadID)
{
    int2 X = direction == 0 ? id.xy : id.yx;
    uint Index = (X.x + X.y*N);//direction == 0 ? (id.x + id.y*N) : (id.y + id.x*N);
    const uint HalfBufferSize = N*N;
    bool WriteBackHalfOfBuffer = true;
    AllMemoryBarrierWithGroupSync();
    //horizontal FFT
    for(int Stage = 0; Stage < LogN; Stage++)//if defining N and LogN in a define and using multi compile, it is possible to unroll this loop, here the gain seems minor enough to ignore it
    {
        const float4 ButterflyData = _butterflyTexture[int2(Stage,id.x)];
        const float2 w = ButterflyData.xy;//twiddle
        const uint ReadOffset = (WriteBackHalfOfBuffer ? 0 : HalfBufferSize);
        const uint WriteOffset = (WriteBackHalfOfBuffer ? HalfBufferSize : 0);
        Complex3 p;
        Complex3 q;
        if(direction == 0)//uniform branch, acceptable
        {
            p = UnifiedFFTBuffer[ButterflyData.z + N*X.y + ReadOffset];
            q = UnifiedFFTBuffer[ButterflyData.w + N*X.y + ReadOffset];
        }else
        {
            p = UnifiedFFTBuffer[X.x + N*ButterflyData.z + ReadOffset];
            q = UnifiedFFTBuffer[X.x + N*ButterflyData.w + ReadOffset];
        }
        
        const Complex3 H = cmp_add(p, cmp_multiply(w, q));
        UnifiedFFTBuffer[Index + WriteOffset] = H;
        
        WriteBackHalfOfBuffer = !WriteBackHalfOfBuffer;
        AllMemoryBarrierWithGroupSync();//this buffer is probably considered device memory 
        
    }
     
     //Vertical FFT
    //  for(int VStage = 0; VStage < LogN; VStage++)
    //  {
    //      AllMemoryBarrierWithGroupSync();
    //      const float4 ButterflyData = _butterflyTexture[int2(VStage,X.y)];
    //      const float2 w = ButterflyData.xy;
    //      const uint ReadOffset = (WriteBackHalfOfBuffer ? 0 : HalfBufferSize);
    //      const uint WriteOffset = (WriteBackHalfOfBuffer ? HalfBufferSize : 0);
    //      const Complex3 p = UnifiedFFTBuffer[X.x + N*ButterflyData.z + ReadOffset];
    //      const Complex3 q = UnifiedFFTBuffer[X.x + N*ButterflyData.w + ReadOffset];
    //      H = cmp_add(p,cmp_multiply(w,q));
    //      UnifiedFFTBuffer[Index + WriteOffset] = H;
    //      if(textureWrite)
    //      {
    //          float2 debugIndex = float2(id.x,id.y + (WriteBackHalfOfBuffer ? N : 0));
    //          DebugFFTTexture[debugIndex.xy] = float4(H.dy,0,1);
    //          DebugFFTTexture[id.xy] = float4(UnifiedFFTBuffer[id.x + N*id.y].dy,0,1);
    //          textureWrite = false;
    //      }
    //      WriteBackHalfOfBuffer = !WriteBackHalfOfBuffer;
    //      AllMemoryBarrierWithGroupSync();
    // }
}

[numthreads(16,16,1)]
void ButterflyHorizontalCompute(uint3 id : SV_DispatchThreadID)
{
    Complex3 H;//H and most the float2 in this kernel are complex numbers, but encapsulating them in struct here is unpractical
    int2 X = id.xy;
    const uint BufferIndex = id.x + id.y*N;
    const float4 ButterFlyData = _butterflyTexture[int2(stage,X.x)];//moved out of the branch
    const float2 w = ButterFlyData.xy;
    if(pingPong == 0)//this branch isn't dynamic so it should be fine
    {
        const Complex3 p = pingPong0[ButterFlyData.z + N*X.y];
        const Complex3 q = pingPong0[ButterFlyData.w + N*X.y];
        
        H = cmp_add(p,cmp_multiply(w,q));
        pingPong1[BufferIndex] = H;
        
    }else//having an additional check here seems pointless
    {
        const Complex3 p = pingPong1[ButterFlyData.z + N*X.y];
        const Complex3 q = pingPong1[ButterFlyData.w + N*X.y];
        H = cmp_add(p,cmp_multiply(w,q));
        pingPong0[BufferIndex] = H;
        
    }
}

[numthreads(16,16,1)]
void ButterflyVerticalCompute(uint3 id : SV_DispatchThreadID)//TODO: the whole fft can be processed in a single call with GroupMemoryBarrierWithGroupSync()
{
    Complex3 H;
    int2 X = id.xy;
    const uint BufferIndex = id.x + id.y*N;
    const float4 data = _butterflyTexture[int2(stage,X.y)];
    const float2 w = data.xy;//just for clarity (although at this point...)
    if(pingPong == 0)
    {
        const Complex3 p = pingPong0[X.x + N*data.z];
        const Complex3 q = pingPong0[X.x + N*data.w];

        H = cmp_add(p, cmp_multiply(w,q));
        pingPong1[BufferIndex] = H;
       

    }else
    {
        const Complex3 p = pingPong1[X.x + N*data.z];
        const Complex3 q = pingPong1[X.x + N*data.w];

        H = cmp_add(p, cmp_multiply(w,q));
        pingPong0[BufferIndex] = H;
        
    }
}
RWTexture2D<float4> displacement;
#ifdef _NORMALMAP
RWTexture2D<float4> normalMap;
float3 getPositionFromDisplacement(uint2 index)
{
    float3 result = displacement[index].xyz;
    uint2 localIndex = index % 2;
    result.xz *= HorizontalScaling;
    result.x += localIndex.x *pixelStep;
    result.z += localIndex.y *pixelStep;
    result.y *= VerticalScaling;
    return result;
}
[numthreads(8,8,1)]
void ComputeNormal(uint3 id : SV_DispatchThreadID)//working on 2x2 pixel quads, choose the number of threads accordingly
{
    const uint2 index00 = id.xy*2;
    const uint2 index01 = uint2(index00.x,index00.y+1);
    const uint2 index10 = uint2(index00.x+1,index00.y);
    const uint2 index11 = uint2(index10.x,index01.y);

    float3 position00 = getPositionFromDisplacement(index00);
    float3 position01 = getPositionFromDisplacement(index01);
    float3 position10 = getPositionFromDisplacement(index10);
    float3 position11 = getPositionFromDisplacement(index11);
    
    const float3 ddx0 = (position00.xyz - position10.xyz)/(position00.x - position10.x);
    const float3 ddx1 = (position01.xyz - position11.xyz)/(position01.x - position11.x);
    const float3 ddy0 = (position00.xyz - position01.xyz)/(position00.z - position01.z);
    const float3 ddy1 = (position10.xyz - position11.xyz)/(position10.z - position11.z);

    float3 normal00 = float3(normalize(cross(ddx0,ddy0)));
    float3 normal01 = float3(normalize(cross(ddx0,ddy1)));
    float3 normal10 = float3(normalize(cross(ddx1,ddy0)));
    float3 normal11 = float3(normalize(cross(ddx1,ddy1)));

    const int sign00 = sign(normal00.y);
    const int sign01 = sign(normal01.y);
    const int sign10 = sign(normal10.y);
    const int sign11 = sign(normal11.y);

    normalMap[index00] = float4(sign00 * normal00,1.0);
    normalMap[index01] = float4(sign01 * normal01,1.0);
    normalMap[index10] = float4(sign10 * normal10,1.0);
    normalMap[index11] = float4(sign11 * normal11,1.0);
    
}
#endif

[numthreads(16,16,1)]
void InversionAndPermutation(uint3 id : SV_DispatchThreadID)
{
    const int2 X = id.xy;
    const uint BufferIndex = id.x + id.y*N;
    
    const float perm = (int(X.x + X.y) & 1) ? -1.0f : 1.0f;//true if x+y is odd
    
    
    Complex3 pingPongData = pingPong0[BufferIndex];//guaranteed to be the correct buffer as there are two passes of equal length
    const float3 h = float3(pingPongData.dx.x,pingPongData.dy.x,pingPongData.dz.x);//taking the real part of all components
    displacement[X] = float4(perm*(h/float(N*N)),1);
}
    float t;//this needs to be "tiled" somehow to not raise forever (and break)
    RWStructuredBuffer<Complex3> tilde_hkt;//a texture buffer might lay this out in memory like a texture
    
    [numthreads(16,16,1)]
    void TimeSpectrum(uint3 id: SV_dispatchThreadID)
    {
        float2 X = float2(id.xy) - (float(N)/2.0);
        float2 K = float2(2.0* M_PI * X.x/L, 2.0 * M_PI * X.y/L);

        float mag = length(K);
        if(mag < 0.00001) mag = 0.00001;

        const float w = sqrt(9.81 * mag);//from sq(w) = g*K used to suppress perpendicular waves
        
        //leaving this commented to show the intent
        // const float2 fourier_amplitude = h0_k[id.xy];
        // const float2 fourier_amplitude_conjugate = h0_MinusK[id.xy];
        float4 fourierAmplitudes = h0[id.xy];
        float cos_wt = cos(w*t);
        float sin_wt = sin(w *t);

        //euler formula
        const float2 exp_iwt = float2(cos_wt,sin_wt);
        const float2 exp_iwt_inv = float2(cos_wt,-sin_wt);
    
        //dy
        const float2 h_kt_dy = cmp_add(cmp_multiply(fourierAmplitudes.xy,exp_iwt)
            ,cmp_multiply(fourierAmplitudes.zw,exp_iwt_inv));
        //dx
        const float2 dx = float2(0.0,-K.x/mag);
        const float2 h_kt_dx = cmp_multiply(dx,h_kt_dy);
        
        //dz
        const float2 dz = float2(0.0,-K.y/mag);
        const float2 h_kt_dz = cmp_multiply(dz, h_kt_dy);
        //const float2 h_kt_dzx = -(h_kt_dy * K.x * K.y * (1/mag));//not very rigorous but it might be correct in this case
        const Complex3 AmplitudeResult = { h_kt_dx, h_kt_dy, h_kt_dz};
        tilde_hkt[id.x + id.y*N] = AmplitudeResult;
    
    }
    RWTexture2D<float4> DebugAmplitudeTexture;
    [numthreads(16,16,1)]
    void DebugAmplitude(uint3 id : SV_dispatchThreadID)
    {
        DebugAmplitudeTexture[id.xy] = float4(tilde_hkt[id.x + id.y*N].dy,0,1);
    }

